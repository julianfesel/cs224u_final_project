{"cells":[{"cell_type":"markdown","metadata":{"id":"noo-CGi1YLBK"},"source":["# Installs"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ycdsv16hhO6e","executionInfo":{"status":"ok","timestamp":1711724263525,"user_tz":-60,"elapsed":1735,"user":{"displayName":"jul val","userId":"14032436987591632045"}},"outputId":"7bc0ecba-749c-42e6-9eec-b34777a1c63d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /mnt/drive; to attempt to forcibly remount, call drive.mount(\"/mnt/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","import sys\n","drive.mount('/mnt/drive')\n","\n","storage_path = \"/mnt/drive/MyDrive/cs224u_final_project\"\n","sys.path.append(storage_path)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ZbcswOgTYKBz","executionInfo":{"status":"ok","timestamp":1711724276309,"user_tz":-60,"elapsed":12787,"user":{"displayName":"jul val","userId":"14032436987591632045"}}},"outputs":[],"source":["%%capture\n","!pip install wget openai datasets pandas pyarrow"]},{"cell_type":"markdown","metadata":{"id":"gxoNgD1fSeRF"},"source":["# Imports"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"zBTUsnAbSfCS","executionInfo":{"status":"ok","timestamp":1711724278672,"user_tz":-60,"elapsed":2369,"user":{"displayName":"jul val","userId":"14032436987591632045"}}},"outputs":[],"source":["import pandas as pd\n","import pyarrow as pa\n","from datasets import Dataset\n","import json"]},{"cell_type":"markdown","metadata":{"id":"zHonyTFza7VY"},"source":["# Load data on rerun and mark faulty"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"OXYjEWCQam3X","executionInfo":{"status":"ok","timestamp":1711724278673,"user_tz":-60,"elapsed":6,"user":{"displayName":"jul val","userId":"14032436987591632045"}},"outputId":"3439e7a8-30e4-4967-fc52-ea8fbd7f1ba7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                    input  \\\n","125472  Jayden gave Emma the balloon the cookie was lo...   \n","124055  Liam hoped that the dog preferred to run Sophi...   \n","78031                                          Liam ran .   \n","114594  The girl forwarded the melon in a house to Emma .   \n","85560                A scientist gave the radio to Emma .   \n","\n","                                                   output         category  \\\n","125472  Jayden ( 38 ) ; Emma ( 17 ) ; * balloon ( 41 )...       length_ood   \n","124055  Liam ( 0 ) ; * dog ( 23 ) ; Sophia ( 50 ) ; Ja...       length_ood   \n","78031      Liam ( 52 ) ; run ( 26 ) AND agent ( 26 , 52 )  in_distribution   \n","114594  * girl ( 53 ) ; * melon ( 18 ) ; house ( 41 ) ...  in_distribution   \n","85560   scientist ( 48 ) ; * radio ( 59 ) ; Emma ( 21 ...  in_distribution   \n","\n","                                             output_renum  \\\n","125472  Jayden ( 1 ) ; Emma ( 2 ) ; * balloon ( 3 ) ; ...   \n","124055  Liam ( 1 ) ; * dog ( 2 ) ; Sophia ( 3 ) ; Jack...   \n","78031          Liam ( 1 ) ; run ( 2 ) AND agent ( 2 , 1 )   \n","114594  * girl ( 1 ) ; * melon ( 2 ) ; house ( 3 ) ; E...   \n","85560   scientist ( 1 ) ; * radio ( 2 ) ; Emma ( 3 ) ;...   \n","\n","                                              gpt35_guide  \\\n","125472  1. Identify entities: Jayden (1); Emma (2); *b...   \n","124055  1. Identify entities: Liam ( 1 ) ; * dog ( 2 )...   \n","78031   1. Identify entities: Liam ( 1 )\\n2. Locate ma...   \n","114594  1. Identify entities: * girl ( 1 ) ; * melon (...   \n","85560   1. Identify entities: scientist ( 1 ) ; * radi...   \n","\n","                                             result_guide  guide_correct  \\\n","125472  1. Identify entities: Jayden (1); Emma (2); *b...          False   \n","124055  1. Identify entities: Liam ( 1 ) ; * dog ( 2 )...          False   \n","78031   1. Identify entities: Liam ( 1 )\\n2. Locate ma...          False   \n","114594  1. Identify entities: * girl ( 1 ) ; * melon (...          False   \n","85560   1. Identify entities: scientist ( 1 ) ; * radi...          False   \n","\n","                                     prompt_training_base  \\\n","125472  <s>[INST] Jayden gave Emma the balloon the coo...   \n","124055  <s>[INST] Liam hoped that the dog preferred to...   \n","78031   <s>[INST] Liam ran . [/INST] Liam ( 1 ) ; run ...   \n","114594  <s>[INST] The girl forwarded the melon in a ho...   \n","85560   <s>[INST] A scientist gave the radio to Emma ....   \n","\n","                                    prompt_training_guide  \\\n","125472  <s>[INST] You are given a sentence and must co...   \n","124055  <s>[INST] You are given a sentence and must co...   \n","78031   <s>[INST] You are given a sentence and must co...   \n","114594  <s>[INST] You are given a sentence and must co...   \n","85560   <s>[INST] You are given a sentence and must co...   \n","\n","        prompt_training_guide_num_token  prompt_training_base_num_token  \\\n","125472                             1346                             161   \n","124055                             1771                             260   \n","78031                              1012                              35   \n","114594                             1230                              94   \n","85560                              1132                              69   \n","\n","        gpt35_guide_num_token  \n","125472                    429  \n","124055                    846  \n","78031                     113  \n","114594                    322  \n","85560                     229  "],"text/html":["\n","  <div id=\"df-41c9a186-620a-4213-bb6f-8d1bc8086f4c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input</th>\n","      <th>output</th>\n","      <th>category</th>\n","      <th>output_renum</th>\n","      <th>gpt35_guide</th>\n","      <th>result_guide</th>\n","      <th>guide_correct</th>\n","      <th>prompt_training_base</th>\n","      <th>prompt_training_guide</th>\n","      <th>prompt_training_guide_num_token</th>\n","      <th>prompt_training_base_num_token</th>\n","      <th>gpt35_guide_num_token</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>125472</th>\n","      <td>Jayden gave Emma the balloon the cookie was lo...</td>\n","      <td>Jayden ( 38 ) ; Emma ( 17 ) ; * balloon ( 41 )...</td>\n","      <td>length_ood</td>\n","      <td>Jayden ( 1 ) ; Emma ( 2 ) ; * balloon ( 3 ) ; ...</td>\n","      <td>1. Identify entities: Jayden (1); Emma (2); *b...</td>\n","      <td>1. Identify entities: Jayden (1); Emma (2); *b...</td>\n","      <td>False</td>\n","      <td>&lt;s&gt;[INST] Jayden gave Emma the balloon the coo...</td>\n","      <td>&lt;s&gt;[INST] You are given a sentence and must co...</td>\n","      <td>1346</td>\n","      <td>161</td>\n","      <td>429</td>\n","    </tr>\n","    <tr>\n","      <th>124055</th>\n","      <td>Liam hoped that the dog preferred to run Sophi...</td>\n","      <td>Liam ( 0 ) ; * dog ( 23 ) ; Sophia ( 50 ) ; Ja...</td>\n","      <td>length_ood</td>\n","      <td>Liam ( 1 ) ; * dog ( 2 ) ; Sophia ( 3 ) ; Jack...</td>\n","      <td>1. Identify entities: Liam ( 1 ) ; * dog ( 2 )...</td>\n","      <td>1. Identify entities: Liam ( 1 ) ; * dog ( 2 )...</td>\n","      <td>False</td>\n","      <td>&lt;s&gt;[INST] Liam hoped that the dog preferred to...</td>\n","      <td>&lt;s&gt;[INST] You are given a sentence and must co...</td>\n","      <td>1771</td>\n","      <td>260</td>\n","      <td>846</td>\n","    </tr>\n","    <tr>\n","      <th>78031</th>\n","      <td>Liam ran .</td>\n","      <td>Liam ( 52 ) ; run ( 26 ) AND agent ( 26 , 52 )</td>\n","      <td>in_distribution</td>\n","      <td>Liam ( 1 ) ; run ( 2 ) AND agent ( 2 , 1 )</td>\n","      <td>1. Identify entities: Liam ( 1 )\\n2. Locate ma...</td>\n","      <td>1. Identify entities: Liam ( 1 )\\n2. Locate ma...</td>\n","      <td>False</td>\n","      <td>&lt;s&gt;[INST] Liam ran . [/INST] Liam ( 1 ) ; run ...</td>\n","      <td>&lt;s&gt;[INST] You are given a sentence and must co...</td>\n","      <td>1012</td>\n","      <td>35</td>\n","      <td>113</td>\n","    </tr>\n","    <tr>\n","      <th>114594</th>\n","      <td>The girl forwarded the melon in a house to Emma .</td>\n","      <td>* girl ( 53 ) ; * melon ( 18 ) ; house ( 41 ) ...</td>\n","      <td>in_distribution</td>\n","      <td>* girl ( 1 ) ; * melon ( 2 ) ; house ( 3 ) ; E...</td>\n","      <td>1. Identify entities: * girl ( 1 ) ; * melon (...</td>\n","      <td>1. Identify entities: * girl ( 1 ) ; * melon (...</td>\n","      <td>False</td>\n","      <td>&lt;s&gt;[INST] The girl forwarded the melon in a ho...</td>\n","      <td>&lt;s&gt;[INST] You are given a sentence and must co...</td>\n","      <td>1230</td>\n","      <td>94</td>\n","      <td>322</td>\n","    </tr>\n","    <tr>\n","      <th>85560</th>\n","      <td>A scientist gave the radio to Emma .</td>\n","      <td>scientist ( 48 ) ; * radio ( 59 ) ; Emma ( 21 ...</td>\n","      <td>in_distribution</td>\n","      <td>scientist ( 1 ) ; * radio ( 2 ) ; Emma ( 3 ) ;...</td>\n","      <td>1. Identify entities: scientist ( 1 ) ; * radi...</td>\n","      <td>1. Identify entities: scientist ( 1 ) ; * radi...</td>\n","      <td>False</td>\n","      <td>&lt;s&gt;[INST] A scientist gave the radio to Emma ....</td>\n","      <td>&lt;s&gt;[INST] You are given a sentence and must co...</td>\n","      <td>1132</td>\n","      <td>69</td>\n","      <td>229</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41c9a186-620a-4213-bb6f-8d1bc8086f4c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-41c9a186-620a-4213-bb6f-8d1bc8086f4c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-41c9a186-620a-4213-bb6f-8d1bc8086f4c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-94786ae9-5e7b-448f-b026-26c02aafae72\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-94786ae9-5e7b-448f-b026-26c02aafae72')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-94786ae9-5e7b-448f-b026-26c02aafae72 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"training_examples_df","summary":"{\n  \"name\": \"training_examples_df\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 495,\n        \"samples\": [\n          \"Emma ate a tool on the rock .\",\n          \"Noah painted a box on the stage .\",\n          \"A cake was eaten by a coach .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"Emma ( 51 ) ; * cake ( 32 ) ; cat ( 27 ) ; post ( 17 ) AND recipient ( 17 , 51 ) AND theme ( 17 , 32 ) AND agent ( 17 , 27 )\",\n          \"Noah ( 42 ) ; box ( 23 ) ; * stage ( 35 ) ; nmod . on ( 23 , 35 ) AND paint ( 9 ) AND agent ( 9 , 42 ) AND theme ( 9 , 23 )\",\n          \"teacher ( 42 ) ; Evelyn ( 51 ) ; like ( 52 ) AND agent ( 52 , 42 ) AND ccomp ( 52 , 7 ) AND smile ( 7 ) AND agent ( 7 , 51 )\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"length_ood\",\n          \"in_distribution\",\n          \"primitive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output_renum\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 497,\n        \"samples\": [\n          \"cake ( 1 ) ; * child ( 2 ) ; * horse ( 3 ) ; pass ( 4 ) AND theme ( 4 , 1 ) AND recipient ( 4 , 2 ) AND agent ( 4 , 3 )\",\n          \"Noah ( 1 ) ; box ( 2 ) ; * stage ( 3 ) ; nmod . on ( 2 , 3 ) AND paint ( 4 ) AND agent ( 4 , 1 ) AND theme ( 4 , 2 )\",\n          \"* chicken ( 7 ) ; Emma ( 2 ) ; frog ( 9 ) ; crayon ( 4 ) ; poet ( 5 ) ; * cake ( 6 ) ; Charlotte ( 7 ) ; hope ( 8 ) AND agent ( 8 , 7 ) AND ccomp ( 8 , 9 ) AND eat ( 9 ) AND agent ( 9 , 2 ) AND wire ( 10 ) AND agent ( 10 , 9 ) AND theme ( 10 , 4 ) AND recipient ( 10 , 5 ) AND eat ( 11 ) AND theme ( 11 , 6 ) AND agent ( 11 , 7 )\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gpt35_guide\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"1. Identify entities: Emma (1) ; * cake (2) ; cat (3)\\n2. Locate main verb/action: posted (4)\\n3. Create relations:\\n   - `recipient(4, 1)` for \\\"Emma\\\" who receives the cake.\\n   - `theme(4, 2)` for \\\"the cake\\\" being delivered.\\n   - `agent(4, 3)` for \\\"a cat\\\" who does the posting.\\n4. Combine relations: Emma (1) ; * cake (2) ; cat (3) AND post (4) AND recipient (4, 1) AND theme (4, 2) AND agent (4, 3)\\n5. Symbols and syntax applied: Emma (1) ; * cake (2) ; cat (3) AND post (4) AND recipient (4, 1) AND theme (4, 2) AND agent (4, 3)\\n6. Return the logical form: Emma (1) ; * cake (2) ; cat (3) AND post (4) AND recipient (4, 1) AND theme (4, 2) AND agent (4, 3)\",\n          \"1. Identify entities: Noah (1); box (2); * stage (3)\\n2. Locate main verb/action: painted (4)\\n3. Create relations:\\n   - `agent (4, 1)` for \\\"Noah\\\" who does the painting.\\n   - `theme (4, 2)` for \\\"a box\\\" being painted.\\n   - `nmod.on (2, 3)` for \\\"on the stage\\\" specifying the location.\\n4. Combine relations: Noah (1) ; box (2) ; * stage (3) ; nmod.on (2, 3) AND paint (4) AND agent (4, 1) AND theme (4, 2)\",\n          \"1. Identify entities: teacher ( 1 ) ; Evelyn ( 2 )\\n2. Locate main verb/action: liked ( 3 ); smiled ( 4 )\\n3. Create relations:\\n   - `agent ( 3 , 1 )` for \\\"A teacher\\\" who likes.\\n   - `ccomp ( 3 , 4 )` for the clause that \\\"liked\\\" comprehends.\\n   - `agent ( 4 , 2 )` for \\\"Evelyn\\\" who smiles.\\n4. Combine relations: teacher ( 1 ) ; Evelyn ( 2 ) AND like ( 3 ) AND agent ( 3 , 1 ) AND ccomp ( 3 , 4 ) AND smile ( 4 ) AND agent ( 4 , 2 )\\n5. Symbols and syntax applied as described, the full correct logical form for \\\"A teacher liked that Evelyn smiled.\\\" is: \\n6. Return the logical form: \\nteacher ( 1 ) ; Evelyn ( 2 ) AND like ( 3 ) AND agent ( 3 , 1 ) AND ccomp ( 3 , 4 ) AND smile ( 4 ) AND agent ( 4 , 2 )\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"result_guide\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 499,\n        \"samples\": [\n          \"Emma ( 1 ) ; tool ( 2 ) ; * rock ( 3 ) ; nmod.on ( 2 , 3 ) AND eat ( 4 ) AND agent ( 4 , 1 ) AND theme ( 4 , 2 )\",\n          \"1. Identify entities: Noah (1); box (2); * stage (3)\\n2. Locate main verb/action: painted (4)\\n3. Create relations:\\n   - `agent (4, 1)` for \\\"Noah\\\" who does the painting.\\n   - `theme (4, 2)` for \\\"a box\\\" being painted.\\n   - `nmod.on (2, 3)` for \\\"on the stage\\\" specifying the location.\\n4. Combine relations: Noah (1) ; box (2) ; * stage (3) ; nmod.on (2, 3) AND paint (4) AND agent (4, 1) AND theme (4, 2)\",\n          \"1. Identify entities: * newspaper ( 1 ) ; Noah ( 2 )\\n2. Locate main verb/action: observed ( 3 )\\n3. Create relations:\\n   - `agent ( 3 , 2 )` for \\\"Noah\\\" who does the observing.\\n   - `theme ( 3 , 1 )` for \\\"the newspaper\\\" being observed.\\n4. Combine relations: `* newspaper ( 1 ) ; Noah ( 2 ) AND observe ( 3 ) AND agent ( 3 , 2 ) AND theme ( 3 , 1 )`\\n5. Symbols and syntax applied as described, the full correct logical form for \\\"The newspaper was observed by Noah.\\\" is: \\n* newspaper ( 1 ) ; Noah ( 2 ) AND observe ( 3 ) AND agent ( 3 , 2 ) AND theme ( 3 , 1 )\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"guide_correct\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt_training_base\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 497,\n        \"samples\": [\n          \"<s>[INST] A cake was passed to the child by the horse . [/INST] cake ( 1 ) ; * child ( 2 ) ; * horse ( 3 ) ; pass ( 4 ) AND theme ( 4 , 1 ) AND recipient ( 4 , 2 ) AND agent ( 4 , 3 )</s>\",\n          \"<s>[INST] Noah painted a box on the stage . [/INST] Noah ( 1 ) ; box ( 2 ) ; * stage ( 3 ) ; nmod . on ( 2 , 3 ) AND paint ( 4 ) AND agent ( 4 , 1 ) AND theme ( 4 , 2 )</s>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt_training_guide\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"<s>[INST] You are given a sentence and must convert it to a specific logical form that represents the semantics of the sentence.\\nTo do this you must follow a step by step guide that you are provided with below.\\nYou must follow the steps and generate answers for each of the steps, while using as few words as possible.\\nThe answer to each step should lead to the logical form, which you return in the last step.\\nFor support, you are also given an example of how to use the step by step guide to convert a given sentence to its logical form.\\n\\n\\n---\\nStep by step guide and demonstration:\\n1. Identify all entities mentioned in the sentence. Assign a unique identifier to each, starting with 1. Mark entities with asterisks if they are introduced by \\\"The\\\" without specific names.\\n2. Locate the main verb or verbs that describe actions, states, or occurrences. Assign identifiers continuing from the last entity. \\n3. Use syntax to create relations:\\n   - `agent(verb_id, entity_id)` indicates the doer of the action.\\n   - `theme(verb_id, entity_id)` indicates what or whom the action is directed towards.\\n   - `recipient(verb_id, entity_id)` for indirect objects receiving the direct object.\\n   - `nmod.prep(related_entity_id, entity_id)` for prepositional phrases, where `prep` is the preposition.\\n   - `ccomp(verb_id, secondary_action_id)` for clauses that the verb comprehends.\\n   - `xcomp(verb_id, secondary_action_id)` for clauses that are an extension of the action.\\n4. Combine relations using `AND` to form the complete logical form.\\n5. Symbols and syntax rules:\\n   - Entities and actions are separated by semicolons (`;`).\\n   - Relations are listed after actions, separated by `AND`.\\n   - Parentheses group the verb or modifier with the involved entities (`relation(id, id)`).\\n   - Asterisks (`*`) mark definite entities without specific identification.\\n6. Return the logical form\\n\\n---\\nDemonstration with example:\\n\\nSentence: The boy returned the girl the raisin in the house.\\n\\n1. Identify entities: * boy ( 1 ) ; * girl ( 2 ) ; * raisin ( 3 ) ; * house ( 4 )\\n2. Locate main verb/action: returned ( 5 )\\n3. Create relations:\\n   - `agent ( 5 , 1 )` for \\\"The boy\\\" who does the returning.\\n   - `recipient ( 5 , 2 )` for \\\"the girl\\\" who receives.\\n   - `theme ( 5 , 3 )` for \\\"the raisin\\\" being returned.\\n   - `nmod.in ( 3 , 4 )` for \\\"in the house\\\" modifying where \\\"the raisin\\\" is.\\n4. Combine relations: `* boy ( 1 ) ; * girl ( 2 ) ; * raisin ( 3 ) ; * house ( 4 ) ; nmod.in ( 3 , 4 ) AND return ( 5 ) AND agent ( 5 , 1 ) AND recipient ( 5 , 2 ) AND theme ( 5 , 3 )`\\n5. Symbols and syntax applied as described, the full correct logical form for \\\"The boy returned the girl the raisin in the house.\\\" is: \\n6. Return the logical form: \\n* boy ( 1 ) ; * girl ( 2 ) ; * raisin ( 3 ) ; * house ( 4 ) ; nmod . in ( 3 , 4 ) AND return ( 5 ) AND agent ( 5 , 1 ) AND recipient ( 5 , 2 ) AND theme ( 5 , 3 )\\n\\n\\n---\\nSentence to convert:\\nEmma was posted the cake by a cat . [/INST] 1. Identify entities: Emma (1) ; * cake (2) ; cat (3)\\n2. Locate main verb/action: posted (4)\\n3. Create relations:\\n   - `recipient(4, 1)` for \\\"Emma\\\" who receives the cake.\\n   - `theme(4, 2)` for \\\"the cake\\\" being delivered.\\n   - `agent(4, 3)` for \\\"a cat\\\" who does the posting.\\n4. Combine relations: Emma (1) ; * cake (2) ; cat (3) AND post (4) AND recipient (4, 1) AND theme (4, 2) AND agent (4, 3)\\n5. Symbols and syntax applied: Emma (1) ; * cake (2) ; cat (3) AND post (4) AND recipient (4, 1) AND theme (4, 2) AND agent (4, 3)\\n6. Return the logical form: Emma (1) ; * cake (2) ; cat (3) AND post (4) AND recipient (4, 1) AND theme (4, 2) AND agent (4, 3)</s>\",\n          \"<s>[INST] You are given a sentence and must convert it to a specific logical form that represents the semantics of the sentence.\\nTo do this you must follow a step by step guide that you are provided with below.\\nYou must follow the steps and generate answers for each of the steps, while using as few words as possible.\\nThe answer to each step should lead to the logical form, which you return in the last step.\\nFor support, you are also given an example of how to use the step by step guide to convert a given sentence to its logical form.\\n\\n\\n---\\nStep by step guide and demonstration:\\n1. Identify all entities mentioned in the sentence. Assign a unique identifier to each, starting with 1. Mark entities with asterisks if they are introduced by \\\"The\\\" without specific names.\\n2. Locate the main verb or verbs that describe actions, states, or occurrences. Assign identifiers continuing from the last entity. \\n3. Use syntax to create relations:\\n   - `agent(verb_id, entity_id)` indicates the doer of the action.\\n   - `theme(verb_id, entity_id)` indicates what or whom the action is directed towards.\\n   - `recipient(verb_id, entity_id)` for indirect objects receiving the direct object.\\n   - `nmod.prep(related_entity_id, entity_id)` for prepositional phrases, where `prep` is the preposition.\\n   - `ccomp(verb_id, secondary_action_id)` for clauses that the verb comprehends.\\n   - `xcomp(verb_id, secondary_action_id)` for clauses that are an extension of the action.\\n4. Combine relations using `AND` to form the complete logical form.\\n5. Symbols and syntax rules:\\n   - Entities and actions are separated by semicolons (`;`).\\n   - Relations are listed after actions, separated by `AND`.\\n   - Parentheses group the verb or modifier with the involved entities (`relation(id, id)`).\\n   - Asterisks (`*`) mark definite entities without specific identification.\\n6. Return the logical form\\n\\n---\\nDemonstration with example:\\n\\nSentence: The boy returned the girl the raisin in the house.\\n\\n1. Identify entities: * boy ( 1 ) ; * girl ( 2 ) ; * raisin ( 3 ) ; * house ( 4 )\\n2. Locate main verb/action: returned ( 5 )\\n3. Create relations:\\n   - `agent ( 5 , 1 )` for \\\"The boy\\\" who does the returning.\\n   - `recipient ( 5 , 2 )` for \\\"the girl\\\" who receives.\\n   - `theme ( 5 , 3 )` for \\\"the raisin\\\" being returned.\\n   - `nmod.in ( 3 , 4 )` for \\\"in the house\\\" modifying where \\\"the raisin\\\" is.\\n4. Combine relations: `* boy ( 1 ) ; * girl ( 2 ) ; * raisin ( 3 ) ; * house ( 4 ) ; nmod.in ( 3 , 4 ) AND return ( 5 ) AND agent ( 5 , 1 ) AND recipient ( 5 , 2 ) AND theme ( 5 , 3 )`\\n5. Symbols and syntax applied as described, the full correct logical form for \\\"The boy returned the girl the raisin in the house.\\\" is: \\n6. Return the logical form: \\n* boy ( 1 ) ; * girl ( 2 ) ; * raisin ( 3 ) ; * house ( 4 ) ; nmod . in ( 3 , 4 ) AND return ( 5 ) AND agent ( 5 , 1 ) AND recipient ( 5 , 2 ) AND theme ( 5 , 3 )\\n\\n\\n---\\nSentence to convert:\\nNoah painted a box on the stage . [/INST] 1. Identify entities: Noah (1); box (2); * stage (3)\\n2. Locate main verb/action: painted (4)\\n3. Create relations:\\n   - `agent (4, 1)` for \\\"Noah\\\" who does the painting.\\n   - `theme (4, 2)` for \\\"a box\\\" being painted.\\n   - `nmod.on (2, 3)` for \\\"on the stage\\\" specifying the location.\\n4. Combine relations: Noah (1) ; box (2) ; * stage (3) ; nmod.on (2, 3) AND paint (4) AND agent (4, 1) AND theme (4, 2)</s>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt_training_guide_num_token\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 168,\n        \"min\": 937,\n        \"max\": 1918,\n        \"num_unique_values\": 273,\n        \"samples\": [\n          1239,\n          1648\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt_training_base_num_token\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 51,\n        \"min\": 33,\n        \"max\": 286,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          176,\n          69\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gpt35_guide_num_token\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 161,\n        \"min\": 36,\n        \"max\": 988,\n        \"num_unique_values\": 265,\n        \"samples\": [\n          264,\n          575\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":4}],"source":["training_examples_df = pd.read_parquet(f\"{storage_path}/gpt35_examples_500_num_tokens.parquet\")\n","training_examples_df.head()"]},{"cell_type":"markdown","metadata":{"id":"ld-J4W_iSlqg"},"source":["# Prepare and train model\n","\n","Adapted from this [notebook](https://colab.research.google.com/drive/1Dyauq4kTZoLewQ1cApceUQVNcnnNTzg_?usp=sharing#scrollTo=2eSvM9zX_2d3)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xv2YPZQW99B9","executionInfo":{"status":"ok","timestamp":1711724326630,"user_tz":-60,"elapsed":47961,"user":{"displayName":"jul val","userId":"14032436987591632045"}},"outputId":"3d18633c-49a9-4b08-f88b-a6880bec839e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git\n","  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-27d3_cby/unsloth_9145815f6cf54b408ce6646117179856\n","  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-27d3_cby/unsloth_9145815f6cf54b408ce6646117179856\n","  Resolved https://github.com/unslothai/unsloth.git to commit a68aebc1fa17755ffbcdafc9239e7ca37ab21657\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tyro in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.7.3)\n","Requirement already satisfied: transformers>=4.38.2 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.38.2)\n","Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.18.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.99)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.66.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n","Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.43.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.25.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.13.3)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.31.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n","Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.9.3)\n","Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.20.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.2->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.2->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.2->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.2)\n","Requirement already satisfied: docstring-parser>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.10.0)\n","Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.7.1)\n","Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.7.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.16.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.4)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n","Requirement already satisfied: xformers in /usr/local/lib/python3.10/dist-packages (0.0.25)\n","Requirement already satisfied: trl in /usr/local/lib/python3.10/dist-packages (0.8.1)\n","Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.10.0)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.28.0)\n","Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.43.0)\n"]}],"source":["import torch\n","major_version, minor_version = torch.cuda.get_device_capability()\n","# Must install separately since Colab has torch 2.2.1, which breaks packages\n","!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n","if major_version >= 8:\n","    # Use this for new GPUs like Ampere, Hopper GPUs (RTX 30xx, RTX 40xx, A100, H100, L40)\n","    !pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes\n","else:\n","    # Use this for older GPUs (V100, Tesla T4, RTX 20xx)\n","    !pip install --no-deps xformers trl peft accelerate bitsandbytes\n","pass"]},{"cell_type":"code","source":["import gc\n","from unsloth import FastLanguageModel\n","import torch\n","from tqdm import tqdm\n","\n","from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n","from transformers import TrainingArguments\n","\n","max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n","dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n","load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n","\n","training_params = [\n","    # (\"base\", 161),\n","    (\"guide\", 50),\n","    (\"base\", 50),\n","    (\"base\", 100),\n","    (\"guide\", 100),\n","    (\"base\", 10),\n","    (\"guide\", 10),\n","]\n","\n","for base_or_guide, num_training in training_params:\n","  print(\"Working on:\", base_or_guide, num_training)\n","  model_name = f\"model_{base_or_guide}_{num_training}\"\n","\n","  try:\n","    del model, tokenizer\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","  except:\n","    pass\n","\n","  model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit)\n","\n","  model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = 0, # Supports any, but = 0 is optimized\n","    bias = \"none\",    # Supports any, but = \"none\" is optimized\n","    use_gradient_checkpointing = True,\n","    random_state = 3407,\n","    use_rslora = False,  # We support rank stabilized LoRA\n","    loftq_config = None, # And LoftQ\n","    )\n","\n","  FastLanguageModel.for_training(model)\n","\n","  dataset_df = training_examples_df.loc[training_examples_df.guide_correct, :].iloc[:num_training, :]\n","  if base_or_guide == \"base\":\n","    train_dataset = Dataset(pa.Table.from_pandas(pd.DataFrame({\"text\": dataset_df.prompt_training_base})))\n","  elif base_or_guide == \"guide\":\n","    train_dataset = Dataset(pa.Table.from_pandas(pd.DataFrame({\"text\": dataset_df.prompt_training_guide})))\n","\n","  collator = DataCollatorForCompletionOnlyLM(tokenizer.encode(\"\\n[/INST]\", add_special_tokens = False)[3:],\n","                                            tokenizer=tokenizer)\n","\n","  trainer = SFTTrainer(\n","      model = model,\n","      tokenizer = tokenizer,\n","      train_dataset = train_dataset,\n","      # formatting_func=formatting_prompts_func,\n","      data_collator=collator,\n","      dataset_text_field = \"text\",\n","      max_seq_length = max_seq_length,\n","      dataset_num_proc = 2,\n","      packing = False, # Can make training 5x faster for short sequences.\n","      args = TrainingArguments(\n","          per_device_train_batch_size = 2,\n","          gradient_accumulation_steps = 4,\n","          warmup_steps = 5,\n","          num_train_epochs=10,\n","          # max_steps = 200,\n","          learning_rate = 2e-4,\n","          fp16 = not torch.cuda.is_bf16_supported(),\n","          bf16 = torch.cuda.is_bf16_supported(),\n","          logging_steps = 1, # max(1, num_training // 8 // 2)\n","          optim = \"adamw_8bit\",\n","          weight_decay = 0.01,\n","          lr_scheduler_type = \"linear\",\n","          seed = 3407,\n","          # save_steps=21,\n","          save_strategy=\"epoch\",\n","          overwrite_output_dir=True,\n","          output_dir = f\"{storage_path}/{model_name}\",\n","      ),\n","  )\n","\n","  results = trainer.train()\n","\n","  with open(f\"{storage_path}/{model_name}_logs.json\", \"w\") as file:\n","    json.dump(trainer.state.log_history, file)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["43dc7030c3c744d6b979e3cf5878b0f5","290a7a0913394f96ae1cf2fc5f6008d6","bf29a8aec0b648768157857a49fd09a6","6a8fb4d78c6940f091bfcea8a6275271","c396364793d648139fceb974587c98ff","9be5c8f1abde4f0d844f47f20556b9f7","3863ca65f8d847e3b4c47184db457fb2","df371548e1d64c90942cfa7122be7bc1","c2c7313eb6be4858a1cf40b480a7d7da","ff241fa20f574e1694a8a8fcdd85482f","0d1462ecfc8b4eaca9aad63a3f7583da","57966158018546d69598ce7d44650474","9e5ae60d205049778eea95c6b9093452","2179cd5970ab4522b13a927d0031a564","e13aa2dccdf64e7fb28d5464086da381","de69a014e643421bb3a064f403d8a421","861e3e85901840c0929e4161084c8738","6f96075510ab4b54854f804d45bbb55a","08fefc69c0ba4572a51ad85ffb7912c2","c24e3be7550141949ec344160067c53b","1f36f9fabe9744e1be88529b29781f50","42bfce7aa279464e89e88203b00f992d","e99789862a79408e83b6cd1bcdee3919","9ba3c4ee278648739d7998c906a16335","b7398d45a0584d898dd592cf74c85f0a","ab9aefe15ba34f4badc31900333e02a5","4fc92984269c430b8321c25523087f37","e46ed2b6514445e09f5d170f7a003214","76258ad6782f4e32bebaaf75dec16ad3","4b6c34450b854f5197a3f3eb5b9e631b","7825437f996c479b9a18bd2da7649c0a","b25cd6dcccaf44b7b3493541af714371","85312a45815d4b259b2c898f8534a036"]},"id":"zwDK1xkRlxOJ","executionInfo":{"status":"error","timestamp":1711727310133,"user_tz":-60,"elapsed":2983520,"user":{"displayName":"jul val","userId":"14032436987591632045"}},"outputId":"c6cb68f1-5ecd-406c-db04-c55438be10ef"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Working on: base 161\n","==((====))==  Unsloth: Fast Mistral patching release 2024.3\n","   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n","O^O/ \\_/ \\    Pytorch: 2.2.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n","\\        /    Bfloat16 = FALSE. Xformers = 0.0.25. FA = False.\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"]},{"output_type":"stream","name":"stderr","text":["Unsloth 2024.3 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"]},{"output_type":"display_data","data":{"text/plain":["Map (num_proc=2):   0%|          | 0/161 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43dc7030c3c744d6b979e3cf5878b0f5"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 161 | Num Epochs = 10\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n","\\        /    Total batch size = 8 | Total steps = 200\n"," \"-____-\"     Number of trainable parameters = 41,943,040\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [200/200 14:25, Epoch 9/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>7.083600</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>6.752300</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>4.783400</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>4.918800</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>4.098100</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>2.818500</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>1.588000</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.730600</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.506200</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.210800</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.355700</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.309200</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.140300</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.136300</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.233200</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.071700</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.109900</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.077400</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.078500</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.148300</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.100500</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.065200</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.041500</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.064000</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.040600</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.012400</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.057500</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.028300</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.070200</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.014800</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>0.060800</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.046600</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>0.088200</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>0.032500</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>0.025100</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>0.016300</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>0.012600</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>0.025400</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>0.014100</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.009100</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>0.010200</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>0.001700</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>0.018400</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>0.021100</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.000300</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>0.006500</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>0.022000</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.002300</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>0.006200</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>0.039600</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>0.011000</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>0.000300</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>0.040900</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>0.048500</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>0.035100</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>0.027100</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.008800</td>\n","    </tr>\n","    <tr>\n","      <td>61</td>\n","      <td>0.003500</td>\n","    </tr>\n","    <tr>\n","      <td>62</td>\n","      <td>0.012400</td>\n","    </tr>\n","    <tr>\n","      <td>63</td>\n","      <td>0.003800</td>\n","    </tr>\n","    <tr>\n","      <td>64</td>\n","      <td>0.013600</td>\n","    </tr>\n","    <tr>\n","      <td>65</td>\n","      <td>0.016300</td>\n","    </tr>\n","    <tr>\n","      <td>66</td>\n","      <td>0.004800</td>\n","    </tr>\n","    <tr>\n","      <td>67</td>\n","      <td>0.016500</td>\n","    </tr>\n","    <tr>\n","      <td>68</td>\n","      <td>0.001800</td>\n","    </tr>\n","    <tr>\n","      <td>69</td>\n","      <td>0.005400</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.002600</td>\n","    </tr>\n","    <tr>\n","      <td>71</td>\n","      <td>0.003100</td>\n","    </tr>\n","    <tr>\n","      <td>72</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>73</td>\n","      <td>0.014500</td>\n","    </tr>\n","    <tr>\n","      <td>74</td>\n","      <td>0.013500</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.001500</td>\n","    </tr>\n","    <tr>\n","      <td>76</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>77</td>\n","      <td>0.004900</td>\n","    </tr>\n","    <tr>\n","      <td>78</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>79</td>\n","      <td>0.008900</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.001600</td>\n","    </tr>\n","    <tr>\n","      <td>81</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>82</td>\n","      <td>0.000200</td>\n","    </tr>\n","    <tr>\n","      <td>83</td>\n","      <td>0.000200</td>\n","    </tr>\n","    <tr>\n","      <td>84</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>85</td>\n","      <td>0.000200</td>\n","    </tr>\n","    <tr>\n","      <td>86</td>\n","      <td>0.009600</td>\n","    </tr>\n","    <tr>\n","      <td>87</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>88</td>\n","      <td>0.000200</td>\n","    </tr>\n","    <tr>\n","      <td>89</td>\n","      <td>0.002400</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.029600</td>\n","    </tr>\n","    <tr>\n","      <td>91</td>\n","      <td>0.006100</td>\n","    </tr>\n","    <tr>\n","      <td>92</td>\n","      <td>0.000300</td>\n","    </tr>\n","    <tr>\n","      <td>93</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>94</td>\n","      <td>0.001300</td>\n","    </tr>\n","    <tr>\n","      <td>95</td>\n","      <td>0.006800</td>\n","    </tr>\n","    <tr>\n","      <td>96</td>\n","      <td>0.003800</td>\n","    </tr>\n","    <tr>\n","      <td>97</td>\n","      <td>0.000200</td>\n","    </tr>\n","    <tr>\n","      <td>98</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>99</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.004100</td>\n","    </tr>\n","    <tr>\n","      <td>101</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>102</td>\n","      <td>0.015900</td>\n","    </tr>\n","    <tr>\n","      <td>103</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>104</td>\n","      <td>0.001700</td>\n","    </tr>\n","    <tr>\n","      <td>105</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>106</td>\n","      <td>0.002400</td>\n","    </tr>\n","    <tr>\n","      <td>107</td>\n","      <td>0.000300</td>\n","    </tr>\n","    <tr>\n","      <td>108</td>\n","      <td>0.000200</td>\n","    </tr>\n","    <tr>\n","      <td>109</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>111</td>\n","      <td>0.003600</td>\n","    </tr>\n","    <tr>\n","      <td>112</td>\n","      <td>0.000200</td>\n","    </tr>\n","    <tr>\n","      <td>113</td>\n","      <td>0.000200</td>\n","    </tr>\n","    <tr>\n","      <td>114</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>115</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>116</td>\n","      <td>0.003900</td>\n","    </tr>\n","    <tr>\n","      <td>117</td>\n","      <td>0.000300</td>\n","    </tr>\n","    <tr>\n","      <td>118</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>119</td>\n","      <td>0.002300</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>121</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>122</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>123</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>124</td>\n","      <td>0.000200</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>126</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>127</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>128</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>129</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>131</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>132</td>\n","      <td>0.000200</td>\n","    </tr>\n","    <tr>\n","      <td>133</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>134</td>\n","      <td>0.000400</td>\n","    </tr>\n","    <tr>\n","      <td>135</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>136</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>137</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>138</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>139</td>\n","      <td>0.000500</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>141</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>142</td>\n","      <td>0.001400</td>\n","    </tr>\n","    <tr>\n","      <td>143</td>\n","      <td>0.000200</td>\n","    </tr>\n","    <tr>\n","      <td>144</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>145</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>146</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>147</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>148</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>149</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>151</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>152</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>153</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>154</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>155</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>156</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>157</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>158</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>159</td>\n","      <td>0.001700</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>161</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>162</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>163</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>164</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>165</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>166</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>167</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>168</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>169</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>171</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>172</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>173</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>174</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>176</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>177</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>178</td>\n","      <td>0.000200</td>\n","    </tr>\n","    <tr>\n","      <td>179</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>181</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>182</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>183</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>184</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>185</td>\n","      <td>0.000200</td>\n","    </tr>\n","    <tr>\n","      <td>186</td>\n","      <td>0.000200</td>\n","    </tr>\n","    <tr>\n","      <td>187</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>188</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>189</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>191</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>192</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>193</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>194</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>195</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>196</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>197</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>198</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>199</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.000100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Working on: guide 50\n","==((====))==  Unsloth: Fast Mistral patching release 2024.3\n","   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n","O^O/ \\_/ \\    Pytorch: 2.2.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n","\\        /    Bfloat16 = FALSE. Xformers = 0.0.25. FA = False.\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"]},{"output_type":"display_data","data":{"text/plain":["Map (num_proc=2):   0%|          | 0/50 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57966158018546d69598ce7d44650474"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 50 | Num Epochs = 10\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n","\\        /    Total batch size = 8 | Total steps = 60\n"," \"-____-\"     Number of trainable parameters = 41,943,040\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [60/60 28:14, Epoch 9/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.308600</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.206600</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.194500</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.193000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.139300</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.109300</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.123600</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.109600</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.067400</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.106000</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.095700</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.057100</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.069500</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.070100</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.058000</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.059300</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.084000</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.039100</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.051400</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.030300</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.050200</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.059100</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.024900</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.032700</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.049900</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.039300</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.031500</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.029100</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.023100</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.028200</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>0.029100</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.024200</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>0.022300</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>0.012400</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>0.023000</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>0.023400</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>0.024300</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>0.016600</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>0.017300</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.027100</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>0.016100</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>0.017800</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>0.015500</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>0.013500</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.011900</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>0.011500</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>0.016500</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>0.014300</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>0.011400</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.014700</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>0.013100</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>0.010000</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>0.009000</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>0.007000</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>0.009100</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>0.011700</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>0.008800</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>0.006400</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>0.013300</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.006800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Working on: base 50\n","==((====))==  Unsloth: Fast Mistral patching release 2024.3\n","   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n","O^O/ \\_/ \\    Pytorch: 2.2.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n","\\        /    Bfloat16 = FALSE. Xformers = 0.0.25. FA = False.\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"]},{"output_type":"display_data","data":{"text/plain":["Map (num_proc=2):   0%|          | 0/50 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e99789862a79408e83b6cd1bcdee3919"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [60/60 04:56, Epoch 9/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>5.824000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>5.298000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>5.801000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>4.607100</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>3.135800</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>1.827100</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>1.296000</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.668800</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.345300</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.257800</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.175500</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.174300</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.162600</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.089300</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.068400</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.075500</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.075900</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.056700</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.060100</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.045600</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.025800</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.016000</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.007300</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.018100</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.023800</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.007800</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.030100</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.001400</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.002300</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.012800</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>0.002700</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.005600</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>0.001400</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>0.003200</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>0.006900</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>0.003500</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>0.001400</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>0.003700</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>0.001500</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>0.002300</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.000300</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>0.000200</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>0.000900</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>0.000200</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>0.000100</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>0.000700</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>0.000800</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>0.000300</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>0.000300</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>0.001000</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.000200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Working on: base 100\n","==((====))==  Unsloth: Fast Mistral patching release 2024.3\n","   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n","O^O/ \\_/ \\    Pytorch: 2.2.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n","\\        /    Bfloat16 = FALSE. Xformers = 0.0.25. FA = False.\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py:1341: UserWarning: Current model requires 134217728.0 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n","  warnings.warn(\n"]},{"output_type":"error","ename":"ValueError","evalue":"\n                    Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the\n                    quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules\n                    in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom `device_map` to\n                    `from_pretrained`. Check\n                    https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\n                    for more details.\n                    ","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-e247076e490f>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m   model, tokenizer = FastLanguageModel.from_pretrained(\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, trust_remote_code, use_gradient_checkpointing, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         model, tokenizer = dispatch_model.from_pretrained(\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0mmodel_name\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unsloth/models/mistral.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, model_patcher, tokenizer_name, trust_remote_code, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0mmax_position_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_max_seq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m    353\u001b[0m             \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0mdevice_map\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    562\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3451\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhf_quantizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3452\u001b[0;31m                 \u001b[0mhf_quantizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3454\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mdevice_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/quantizers/quantizer_bnb_4bit.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m             }\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevice_map_without_lm_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"disk\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevice_map_without_lm_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m     87\u001b[0m                     \"\"\"\n\u001b[1;32m     88\u001b[0m                     \u001b[0mSome\u001b[0m \u001b[0mmodules\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdispatched\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCPU\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdisk\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mMake\u001b[0m \u001b[0msure\u001b[0m \u001b[0myou\u001b[0m \u001b[0mhave\u001b[0m \u001b[0menough\u001b[0m \u001b[0mGPU\u001b[0m \u001b[0mRAM\u001b[0m \u001b[0mto\u001b[0m \u001b[0mfit\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: \n                    Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the\n                    quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules\n                    in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom `device_map` to\n                    `from_pretrained`. Check\n                    https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\n                    for more details.\n                    "]}]},{"cell_type":"code","source":[],"metadata":{"id":"PU4YK1TSsDlU","executionInfo":{"status":"aborted","timestamp":1711727310134,"user_tz":-60,"elapsed":23,"user":{"displayName":"jul val","userId":"14032436987591632045"}}},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1HdRHAAdsmgz6YP562fUgx7N7TDtzSBI8","timestamp":1711711644976}],"gpuType":"T4","authorship_tag":"ABX9TyMhsmvMEo21UG3IMLbe9z2y"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"43dc7030c3c744d6b979e3cf5878b0f5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_290a7a0913394f96ae1cf2fc5f6008d6","IPY_MODEL_bf29a8aec0b648768157857a49fd09a6","IPY_MODEL_6a8fb4d78c6940f091bfcea8a6275271"],"layout":"IPY_MODEL_c396364793d648139fceb974587c98ff"}},"290a7a0913394f96ae1cf2fc5f6008d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9be5c8f1abde4f0d844f47f20556b9f7","placeholder":"","style":"IPY_MODEL_3863ca65f8d847e3b4c47184db457fb2","value":"Map(num_proc=2):100%"}},"bf29a8aec0b648768157857a49fd09a6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_df371548e1d64c90942cfa7122be7bc1","max":161,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c2c7313eb6be4858a1cf40b480a7d7da","value":161}},"6a8fb4d78c6940f091bfcea8a6275271":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff241fa20f574e1694a8a8fcdd85482f","placeholder":"","style":"IPY_MODEL_0d1462ecfc8b4eaca9aad63a3f7583da","value":"161/161[00:00&lt;00:00,237.28examples/s]"}},"c396364793d648139fceb974587c98ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9be5c8f1abde4f0d844f47f20556b9f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3863ca65f8d847e3b4c47184db457fb2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df371548e1d64c90942cfa7122be7bc1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2c7313eb6be4858a1cf40b480a7d7da":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ff241fa20f574e1694a8a8fcdd85482f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d1462ecfc8b4eaca9aad63a3f7583da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57966158018546d69598ce7d44650474":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9e5ae60d205049778eea95c6b9093452","IPY_MODEL_2179cd5970ab4522b13a927d0031a564","IPY_MODEL_e13aa2dccdf64e7fb28d5464086da381"],"layout":"IPY_MODEL_de69a014e643421bb3a064f403d8a421"}},"9e5ae60d205049778eea95c6b9093452":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_861e3e85901840c0929e4161084c8738","placeholder":"","style":"IPY_MODEL_6f96075510ab4b54854f804d45bbb55a","value":"Map(num_proc=2):100%"}},"2179cd5970ab4522b13a927d0031a564":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_08fefc69c0ba4572a51ad85ffb7912c2","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c24e3be7550141949ec344160067c53b","value":50}},"e13aa2dccdf64e7fb28d5464086da381":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f36f9fabe9744e1be88529b29781f50","placeholder":"","style":"IPY_MODEL_42bfce7aa279464e89e88203b00f992d","value":"50/50[00:00&lt;00:00,53.16examples/s]"}},"de69a014e643421bb3a064f403d8a421":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"861e3e85901840c0929e4161084c8738":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f96075510ab4b54854f804d45bbb55a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08fefc69c0ba4572a51ad85ffb7912c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c24e3be7550141949ec344160067c53b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1f36f9fabe9744e1be88529b29781f50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42bfce7aa279464e89e88203b00f992d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e99789862a79408e83b6cd1bcdee3919":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9ba3c4ee278648739d7998c906a16335","IPY_MODEL_b7398d45a0584d898dd592cf74c85f0a","IPY_MODEL_ab9aefe15ba34f4badc31900333e02a5"],"layout":"IPY_MODEL_4fc92984269c430b8321c25523087f37"}},"9ba3c4ee278648739d7998c906a16335":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e46ed2b6514445e09f5d170f7a003214","placeholder":"","style":"IPY_MODEL_76258ad6782f4e32bebaaf75dec16ad3","value":"Map(num_proc=2):100%"}},"b7398d45a0584d898dd592cf74c85f0a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b6c34450b854f5197a3f3eb5b9e631b","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7825437f996c479b9a18bd2da7649c0a","value":50}},"ab9aefe15ba34f4badc31900333e02a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b25cd6dcccaf44b7b3493541af714371","placeholder":"","style":"IPY_MODEL_85312a45815d4b259b2c898f8534a036","value":"50/50[00:00&lt;00:00,64.25examples/s]"}},"4fc92984269c430b8321c25523087f37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e46ed2b6514445e09f5d170f7a003214":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76258ad6782f4e32bebaaf75dec16ad3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b6c34450b854f5197a3f3eb5b9e631b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7825437f996c479b9a18bd2da7649c0a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b25cd6dcccaf44b7b3493541af714371":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85312a45815d4b259b2c898f8534a036":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}